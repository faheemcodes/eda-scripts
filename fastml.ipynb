{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "def fastml(problem_type, models, y, drops, tresh_unique, tresh_missing, train, test):\n",
    "    \n",
    "    '''\n",
    "    Takes in several inputs regarding the ML problem and carries out pre-processing, model fitting and \n",
    "    cross validation to provide accuracy score and comparison between various models.\n",
    "    \n",
    "    Inputs :\n",
    "    -------\n",
    "    problem_type : 'Regression' or 'Classification'\n",
    "    models  :  [LinearRegression(), KNeighborsRegressor(), RandomForestRegressor()] choose any of these for regression \n",
    "               [LogisticRegression(), RandomForestClassifier(), KNeighborsClassifier(), \n",
    "               GaussianNB(), LinearSVC(), SGDClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier()] \n",
    "               choose any of these for classification\n",
    "    y       : Column name of the dependant variable as a string \n",
    "    drops   : List of column names to be removed prior to modeling\n",
    "    tresh_unique   : If the number of unique items in a categorical columns exceed this treshold, the column is dropped\n",
    "              If the number of unique items in a categorical columns exceed this treshold, the column is not dummified\n",
    "    tresh_missing   : If the % of missing items in a column exceed this treshold, the column is dropped\n",
    "\n",
    "    train   : Training set (dataframe)\n",
    "    test    : Testing set (dataframe) is the data on which the model need to be applied\n",
    "              All the columns (except dependant variable) need to be same as that of the training set\n",
    "              Test dataset is optional.\n",
    "    \n",
    "    Outputs : \n",
    "    --------\n",
    "    data    : A list of various datasets processed and predicted as part of the analysis\n",
    "              data[0] --> X_train - dataframe of features of training set \n",
    "              data[1] --> X_val - dataframe of features of validation set \n",
    "              data[2] --> y_train - dataframe of dependant variable of training set\n",
    "              data[3] --> y_val - dataframe of dependant variable of validation set\n",
    "              data[4] --> X_test - dataframe of the features of the test set on which the model was applied\n",
    "              data[5] --> y_pred - dataframe containing predictions based on the test data set using all models\n",
    "              \n",
    "    df_eval : A dataframe comparing accuracy scores among various models.\n",
    "    \n",
    "    \n",
    "    Examples :\n",
    "    ---------\n",
    "    For titanic dataset, \n",
    "    \n",
    "    >>> train = pd.read_csv(path+'train.csv')\n",
    "    >>> test = pd.read_csv(path+'test.csv')\n",
    "\n",
    "    >>> models = [LogisticRegression(), RandomForestClassifier(), KNeighborsClassifier()]\n",
    "    >>> drops = ['PassengerId']\n",
    "\n",
    "    >>> data, df_eval = df_run('Classification', models, 'Survived', drops, 20, 40, train, test)\n",
    "    \n",
    "    >>> print(df_eval)\n",
    "    \n",
    "              LogisticRegression  RandomForestClassifier  KNeighborsClassifier\n",
    "    R2_train                0.82                    0.98                  0.79\n",
    "    R2_val                  0.79                    0.80                  0.69\n",
    "    Time                   27.88                  212.43                 34.91\n",
    "    '''\n",
    "    \n",
    "    y_train = [] \n",
    "    df_train = train.copy()\n",
    "    \n",
    "    if y in df_train.columns:\n",
    "        y_train = df_train[y]\n",
    "        df_train.drop(y,axis=1,inplace=True)\n",
    "    else:\n",
    "        print('Dependent variable not found in the train data frame')\n",
    "        sys.exit()\n",
    "    \n",
    "    if not test.empty:\n",
    "        df_test = test.copy()\n",
    "        df = pd.concat([df_train, df_test], axis=0)\n",
    "    else: \n",
    "        df = df_train\n",
    "\n",
    "    df = del_cols(df, drops, tresh_unique, tresh_missing)\n",
    "    cat_names = cat_cols(df)\n",
    "    cont_names = num_cols(df)\n",
    "\n",
    "    df = fill_missing(df)\n",
    "    df = dummify(df,tresh_unique)\n",
    "    \n",
    "    X_train = df[:len(df_train)]\n",
    "    X_test = [] \n",
    "    if not test.empty:\n",
    "        X_test = df[len(df_train):]\n",
    "    \n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)\n",
    "     \n",
    "    df_eval, y_pred = calcs(problem_type, models, X_train, X_val, y_train, y_val, X_test)\n",
    "    \n",
    "    data = [X_train, X_val, y_train, y_val, X_test, y_pred]\n",
    "\n",
    "    return data, df_eval\n",
    "            \n",
    "def calcs(problem_type, models, X_train, X_val, y_train, y_val, X_test):\n",
    "    '''\n",
    "    Based on the models specified in the input list, this function will run regression models on train and validation datasets.\n",
    "    Outputs various accuracy and error parameters with a comparison view of all the models.\n",
    "    '''\n",
    "\n",
    "    df_eval = pd.DataFrame(columns=[''])\n",
    "    y_test = {}\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        tic = time.time()\n",
    "        model = model.fit(X_train, y_train)\n",
    "        pred_val = model.predict(X_val)\n",
    "        decimals = 4\n",
    "        \n",
    "        if problem_type == 'Regression':\n",
    "            \n",
    "            evaluation = {\n",
    "                            'R2_train' : round(model.score(X_train,y_train),decimals),\n",
    "                            'R2_val' : round(model.score(X_val,y_val),decimals),\n",
    "                            'MAE_val' : round(metrics.mean_absolute_error(y_val,pred_val),decimals), \n",
    "                            'RMSE_val' : round(np.sqrt(metrics.mean_squared_error(y_val,pred_val)),decimals),\n",
    "                            'Time' : round((time.time() - tic)*1000,decimals)\n",
    "                         }\n",
    "        elif problem_type == 'Classification':\n",
    "            \n",
    "            evaluation = {\n",
    "                            'R2_train' : round(model.score(X_train, y_train),decimals),\n",
    "                            'R2_val' : round(metrics.accuracy_score(y_val,pred_val),decimals),\n",
    "                            'Time' : round((time.time() - tic)*1000,decimals)\n",
    "                         }\n",
    "        else:\n",
    "            print('Problem type has to be either Classification or Regression')\n",
    "            sys.exit()\n",
    "            \n",
    "        df_temp = pd.DataFrame.from_dict(evaluation, orient='index', columns=[str(model).split('(')[0]])\n",
    "        df_eval = pd.concat([df_eval,df_temp],axis=1)\n",
    "        \n",
    "        y_test[str(model).split('(')[0]] = model.predict(X_test)\n",
    "            \n",
    "    df_eval.drop(df_eval.columns[0], axis=1, inplace=True)\n",
    "    y_pred = pd.DataFrame.from_dict(y_test, orient='columns')\n",
    "\n",
    "    return df_eval, y_pred\n",
    "\n",
    "def display_all(df):\n",
    "    '''\n",
    "    display more rows and columns of a dataframe in ipython\n",
    "    '''\n",
    "    with pd.option_context('display.max_rows', 1000, 'display.max_columns', 1000):\n",
    "        display(df)\n",
    "        \n",
    "def num_cols (df):\n",
    "    '''\n",
    "    returns a list containing the names of the columns that are numerical (either float or integer).\n",
    "    '''\n",
    "    num_names=[]\n",
    "    for col in df.columns:\n",
    "        if is_numeric_dtype(df[col]):\n",
    "            num_names.append(col)\n",
    "    return num_names\n",
    "      \n",
    "def cat_cols (df):\n",
    "    '''\n",
    "    returns a list containing the names of the columns that are categorical.\n",
    "    '''\n",
    "    cat_names=[]\n",
    "    for col in df.columns:\n",
    "        if not is_numeric_dtype(df[col]):\n",
    "            cat_names.append(col)\n",
    "    return cat_names\n",
    "\n",
    "def del_cols(df, drops, tresh_unique=20, tresh_missing=50):\n",
    "    '''\n",
    "    deletes columns based on either of the following three conditions:\n",
    "    1. categorical columns which has more unique items than the treshold value (tresh_unique) \n",
    "    2. columns that are part of the list \"drops\"\n",
    "    3. columns containing % of missing values that are greater than the treshold value (tresh_missing)\n",
    "    '''\n",
    "    for col in cat_cols(df):\n",
    "        if len(df[col].unique()) > tresh_unique:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            \n",
    "    df.drop(drops, axis=1, inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if ((df[col].isnull().sum())/len(df))*100 >= tresh_missing:\n",
    "            df[col+'_na'] = pd.isnull(df[col])\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def dummify(df, tresh_unique=20, inplace=True):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) <= tresh_unique and df[col].dtypes.name != 'bool':\n",
    "            cols.append(col)\n",
    "    df_temp = df[cols]\n",
    "    df_temp = pd.get_dummies(df_temp.astype(str), columns=cols, drop_first=True)\n",
    "    df.drop(cols, axis=1, inplace=inplace)\n",
    "    df = pd.concat([df,df_temp], axis=1)\n",
    "    return df\n",
    "\n",
    "def fill_missing(df):\n",
    "    for col in df.columns:\n",
    "        if pd.isnull(df[col]).sum():\n",
    "            if is_numeric_dtype(df[col]):\n",
    "                filler = df[col].mean()\n",
    "            else:\n",
    "                filler = df[col].mode()[0]\n",
    "            df[col+'_fill'] = df[col].fillna(filler)\n",
    "            df[col+'_na'] = pd.isnull(df[col])\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
